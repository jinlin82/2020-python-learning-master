{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Exercise 8: Clustering stocks using KMeans\n",
                "\n",
                "In this exercise, you'll cluster companies using their daily stock price movements (i.e. the dollar difference between the closing and opening prices for each trading day).  You are given a NumPy array `movements` of daily price movements from 2010 to 2015, where each row corresponds to a company, and each column corresponds to a trading day.\n",
                "\n",
                "Some stocks are more expensive than others.  To account for this, include a `Normalizer` at the beginning of your pipeline.  The Normalizer will separately transform each company's stock price to a relative scale before the clustering begins.\n",
                "\n",
                "## Normalizer vs StandardScaler\n",
                "Note that `Normalizer()` is different to `StandardScaler()`, which you used in the previous exercise. While `StandardScaler()` standardizes **features** (such as the features of the fish data from the previous exercise) by removing the mean and scaling to unit variance, `Normalizer()` rescales **each sample** - here, each company's stock price - independently of the other.\n",
                "\n",
                "This dataset was obtained from the Yahoo! Finance API."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "From the course _Transition to Data Science_. [Buy the entire course for just $10](https://www.udemy.com/transition-to-data-science-in-python/?couponCode=CLUSTER-NBS) for many more exercises and helpful video lectures."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Step 1:** Load the data _(written for you)_"
            ],
            "metadata": {}
        },
        {
            "execution_count": 1,
            "cell_type": "code",
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "fn = '../datasets/company-stock-movements-2010-2015-incl.csv'\n",
                "stocks_df = pd.read_csv(fn, index_col=0)"
            ],
            "metadata": {
                "exercise": false,
                "collapsed": true
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Step 2:** Inspect the first few rows of the DataFrame `stocks_df` by calling its `head()` function."
            ],
            "metadata": {}
        },
        {
            "execution_count": 2,
            "cell_type": "code",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "                  2010-01-04  2010-01-05  2010-01-06  2010-01-07  2010-01-08  \\\nApple               0.580000   -0.220005   -3.409998   -1.170000    1.680011   \nAIG                -0.640002   -0.650000   -0.210001   -0.420000    0.710001   \nAmazon             -2.350006    1.260009   -2.350006   -2.009995    2.960006   \nAmerican express    0.109997    0.000000    0.260002    0.720002    0.190003   \nBoeing              0.459999    1.770000    1.549999    2.690003    0.059997   \n\n                  2010-01-11  2010-01-12  2010-01-13  2010-01-14  2010-01-15  \\\nApple              -2.689994   -1.469994    2.779997   -0.680003   -4.999995   \nAIG                -0.200001   -1.130001    0.069999   -0.119999   -0.500000   \nAmazon             -2.309997   -1.640007    1.209999   -1.790001   -2.039994   \nAmerican express   -0.270001    0.750000    0.300004    0.639999   -0.130001   \nBoeing             -1.080002    0.360000    0.549999    0.530002   -0.709999   \n\n                  ...  2013-10-16  2013-10-17  2013-10-18  2013-10-21  \\\nApple             ...    0.320008    4.519997    2.899987    9.590019   \nAIG               ...    0.919998    0.709999    0.119999   -0.480000   \nAmazon            ...    2.109985    3.699982    9.570008   -3.450013   \nAmerican express  ...    0.680001    2.290001    0.409996   -0.069999   \nBoeing            ...    1.559997    2.480003    0.019997   -1.220001   \n\n                  2013-10-22  2013-10-23  2013-10-24  2013-10-25  2013-10-28  \\\nApple              -6.540016    5.959976    6.910011   -5.359962    0.840019   \nAIG                 0.010002   -0.279998   -0.190003   -0.040001   -0.400002   \nAmazon              4.820008   -4.079986    2.579986    4.790009   -1.760009   \nAmerican express    0.100006    0.069999    0.130005    1.849999    0.040001   \nBoeing              0.480003    3.020004   -0.029999    1.940002    1.130005   \n\n                  2013-10-29  \nApple             -19.589981  \nAIG                 0.660000  \nAmazon              3.740021  \nAmerican express    0.540001  \nBoeing              0.309998  \n\n[5 rows x 963 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2010-01-04</th>\n      <th>2010-01-05</th>\n      <th>2010-01-06</th>\n      <th>2010-01-07</th>\n      <th>2010-01-08</th>\n      <th>2010-01-11</th>\n      <th>2010-01-12</th>\n      <th>2010-01-13</th>\n      <th>2010-01-14</th>\n      <th>2010-01-15</th>\n      <th>...</th>\n      <th>2013-10-16</th>\n      <th>2013-10-17</th>\n      <th>2013-10-18</th>\n      <th>2013-10-21</th>\n      <th>2013-10-22</th>\n      <th>2013-10-23</th>\n      <th>2013-10-24</th>\n      <th>2013-10-25</th>\n      <th>2013-10-28</th>\n      <th>2013-10-29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Apple</th>\n      <td>0.580000</td>\n      <td>-0.220005</td>\n      <td>-3.409998</td>\n      <td>-1.170000</td>\n      <td>1.680011</td>\n      <td>-2.689994</td>\n      <td>-1.469994</td>\n      <td>2.779997</td>\n      <td>-0.680003</td>\n      <td>-4.999995</td>\n      <td>...</td>\n      <td>0.320008</td>\n      <td>4.519997</td>\n      <td>2.899987</td>\n      <td>9.590019</td>\n      <td>-6.540016</td>\n      <td>5.959976</td>\n      <td>6.910011</td>\n      <td>-5.359962</td>\n      <td>0.840019</td>\n      <td>-19.589981</td>\n    </tr>\n    <tr>\n      <th>AIG</th>\n      <td>-0.640002</td>\n      <td>-0.650000</td>\n      <td>-0.210001</td>\n      <td>-0.420000</td>\n      <td>0.710001</td>\n      <td>-0.200001</td>\n      <td>-1.130001</td>\n      <td>0.069999</td>\n      <td>-0.119999</td>\n      <td>-0.500000</td>\n      <td>...</td>\n      <td>0.919998</td>\n      <td>0.709999</td>\n      <td>0.119999</td>\n      <td>-0.480000</td>\n      <td>0.010002</td>\n      <td>-0.279998</td>\n      <td>-0.190003</td>\n      <td>-0.040001</td>\n      <td>-0.400002</td>\n      <td>0.660000</td>\n    </tr>\n    <tr>\n      <th>Amazon</th>\n      <td>-2.350006</td>\n      <td>1.260009</td>\n      <td>-2.350006</td>\n      <td>-2.009995</td>\n      <td>2.960006</td>\n      <td>-2.309997</td>\n      <td>-1.640007</td>\n      <td>1.209999</td>\n      <td>-1.790001</td>\n      <td>-2.039994</td>\n      <td>...</td>\n      <td>2.109985</td>\n      <td>3.699982</td>\n      <td>9.570008</td>\n      <td>-3.450013</td>\n      <td>4.820008</td>\n      <td>-4.079986</td>\n      <td>2.579986</td>\n      <td>4.790009</td>\n      <td>-1.760009</td>\n      <td>3.740021</td>\n    </tr>\n    <tr>\n      <th>American express</th>\n      <td>0.109997</td>\n      <td>0.000000</td>\n      <td>0.260002</td>\n      <td>0.720002</td>\n      <td>0.190003</td>\n      <td>-0.270001</td>\n      <td>0.750000</td>\n      <td>0.300004</td>\n      <td>0.639999</td>\n      <td>-0.130001</td>\n      <td>...</td>\n      <td>0.680001</td>\n      <td>2.290001</td>\n      <td>0.409996</td>\n      <td>-0.069999</td>\n      <td>0.100006</td>\n      <td>0.069999</td>\n      <td>0.130005</td>\n      <td>1.849999</td>\n      <td>0.040001</td>\n      <td>0.540001</td>\n    </tr>\n    <tr>\n      <th>Boeing</th>\n      <td>0.459999</td>\n      <td>1.770000</td>\n      <td>1.549999</td>\n      <td>2.690003</td>\n      <td>0.059997</td>\n      <td>-1.080002</td>\n      <td>0.360000</td>\n      <td>0.549999</td>\n      <td>0.530002</td>\n      <td>-0.709999</td>\n      <td>...</td>\n      <td>1.559997</td>\n      <td>2.480003</td>\n      <td>0.019997</td>\n      <td>-1.220001</td>\n      <td>0.480003</td>\n      <td>3.020004</td>\n      <td>-0.029999</td>\n      <td>1.940002</td>\n      <td>1.130005</td>\n      <td>0.309998</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 963 columns</p>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 2
                }
            ],
            "source": [
                "stocks_df.head()"
            ],
            "metadata": {
                "collapsed": false
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Step 3:** Extract the NumPy array `movements` from the DataFrame and the list of company names (_written for you_)"
            ],
            "metadata": {}
        },
        {
            "execution_count": 3,
            "cell_type": "code",
            "outputs": [],
            "source": [
                "companies = list(stocks_df.index)\n",
                "movements = stocks_df.values"
            ],
            "metadata": {
                "exercise": false,
                "collapsed": true
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Step 4:** Make the necessary imports:\n",
                "\n",
                "- `Normalizer` from `sklearn.preprocessing`.\n",
                "- `KMeans` from `sklearn.cluster`.\n",
                "- `make_pipeline` from `sklearn.pipeline`."
            ],
            "metadata": {}
        },
        {
            "execution_count": 6,
            "cell_type": "code",
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import Normalizer \n",
                "from sklearn.cluster import KMeans \n",
                "from sklearn.pipeline import make_pipeline"
            ],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Step 3:** Create an instance of `Normalizer` called `normalizer`."
            ],
            "metadata": {}
        },
        {
            "execution_count": 7,
            "cell_type": "code",
            "outputs": [],
            "source": [
                "normalizer = Normalizer()"
            ],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Step 4:** Create an instance of `KMeans` called `kmeans` with `14` clusters."
            ],
            "metadata": {}
        },
        {
            "execution_count": 8,
            "cell_type": "code",
            "outputs": [],
            "source": [
                "kmeans = KMeans(n_clusters=14)"
            ],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Step 5:** Using `make_pipeline()`, create a pipeline called `pipeline` that chains `normalizer` and `kmeans`."
            ],
            "metadata": {}
        },
        {
            "execution_count": 9,
            "cell_type": "code",
            "outputs": [],
            "source": [
                "pipeline = make_pipeline(normalizer,kmeans)"
            ],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Step 6:** Fit the pipeline to the `movements` array."
            ],
            "metadata": {}
        },
        {
            "execution_count": 10,
            "cell_type": "code",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "Pipeline(memory=None,\n         steps=[('normalizer', Normalizer(copy=True, norm='l2')),\n                ('kmeans',\n                 KMeans(algorithm='auto', copy_x=True, init='k-means++',\n                        max_iter=300, n_clusters=14, n_init=10, n_jobs=None,\n                        precompute_distances='auto', random_state=None,\n                        tol=0.0001, verbose=0))],\n         verbose=False)"
                    },
                    "metadata": {},
                    "execution_count": 10
                }
            ],
            "source": [
                "pipeline.fit(movements)"
            ],
            "metadata": {
                "collapsed": false
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**In the next exercise:** Let's check out your clustering!"
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3",
            "language": "python"
        },
        "language_info": {
            "codemirror_mode": {
                "version": 3,
                "name": "ipython"
            },
            "version": "3.7.6-final",
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}